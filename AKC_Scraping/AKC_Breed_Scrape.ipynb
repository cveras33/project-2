{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import selenium\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_browser():\n",
    "    # @NOTE: Replace the path with your actual path to the chromedriver\n",
    "    executable_path = {\"executable_path\": ChromeDriverManager().install()}\n",
    "    return Browser(\"chrome\", **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 87.0.4280\n",
      "[WDM] - Get LATEST driver version for 87.0.4280\n",
      "[WDM] - There is no [win32] chromedriver for browser 87.0.4280 in cache\n",
      "[WDM] - Get LATEST driver version for 87.0.4280\n",
      "[WDM] - Trying to download new driver from http://chromedriver.storage.googleapis.com/87.0.4280.88/chromedriver_win32.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Driver has been saved in cache [C:\\Users\\jvolo\\.wdm\\drivers\\chromedriver\\win32\\87.0.4280.88]\n"
     ]
    }
   ],
   "source": [
    "browser = init_browser()\n",
    "url = \"https://www.akc.org/dog-breeds/\"\n",
    "browser.visit(url)\n",
    "\n",
    "#THERE ARE 24 PAGES OF DOG BREEDS\n",
    "#https://www.akc.org/dog-breeds/page/24/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e5f9c6366239>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m#####COLLECT DOG BREED NAME#####\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mdog_breed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"h1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mdog_breed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdog_breed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_text'"
     ]
    }
   ],
   "source": [
    "breeds_list_of_dicts = []\n",
    "\n",
    "for p in range(24):\n",
    "    color_list = []\n",
    "    final_color_list = []\n",
    "    p += 1\n",
    "    #####GO TO NEW BREED PAGE#####\n",
    "    url = f\"https://www.akc.org/dog-breeds/page/{p}/\"\n",
    "    browser.visit(url)\n",
    "    \n",
    "    for i in range(12):\n",
    "        html = browser.html\n",
    "        soup = bs(html, \"html.parser\")\n",
    "        \n",
    "        #####GO TO BREED DETAIL PAGE#####\n",
    "        browser.find_by_css('a[class=\"d-block relative\"]')[i].click()\n",
    "        time.sleep(1)\n",
    "        \n",
    "        html = browser.html\n",
    "        soup = bs(html, \"html.parser\")\n",
    "        \n",
    "        \n",
    "        #####COLLECT DOG BREED NAME#####\n",
    "        dog_breed = soup.find(\"h1\").get_text()\n",
    "        dog_breed = dog_breed.replace('\\n', '').strip(\" \")\n",
    "        \n",
    "        #####COLLECT DOG ATTRIBUTES#####\n",
    "        attribute_block = soup.find_all(\"span\", class_=\"attribute-list__description\")\n",
    "        \n",
    "        if len(attribute_block) == 6:\n",
    "            temperment = soup.find(\"span\", class_=\"attribute-list__description attribute-list__text attribute-list__text--lg mb4 bpm-mb5 pb0 d-block\").get_text()\n",
    "            akc_rank = soup.find_all(\"span\", class_=\"attribute-list__description attribute-list__text\")[0].get_text()\n",
    "            height = soup.find_all(\"span\", class_=\"attribute-list__description attribute-list__text\")[1].get_text()\n",
    "            weight = soup.find_all(\"span\", class_=\"attribute-list__description attribute-list__text\")[2].get_text()\n",
    "            life_ex = soup.find_all(\"span\", class_=\"attribute-list__description attribute-list__text\")[3].get_text()\n",
    "            group = soup.find_all(\"span\", class_=\"attribute-list__description attribute-list__text\")[4].get_text()\n",
    "        elif len(attribute_block) == 5: \n",
    "            temperment = soup.find(\"span\", class_=\"attribute-list__description attribute-list__text attribute-list__text--lg mb4 bpm-mb5 pb0 d-block\").get_text()\n",
    "            height = soup.find_all(\"span\", class_=\"attribute-list__description attribute-list__text\")[0].get_text()\n",
    "            weight = soup.find_all(\"span\", class_=\"attribute-list__description attribute-list__text\")[1].get_text()\n",
    "            life_ex = soup.find_all(\"span\", class_=\"attribute-list__description attribute-list__text\")[2].get_text()\n",
    "            group = soup.find_all(\"span\", class_=\"attribute-list__description attribute-list__text\")[3].get_text()\n",
    "            akc_rank = \"NA\"\n",
    "        elif len(attribute_block) == 4:\n",
    "            temperment = soup.find(\"span\", class_=\"attribute-list__description attribute-list__text attribute-list__text--lg mb4 bpm-mb5 pb0 d-block\").get_text()\n",
    "            height = soup.find_all(\"span\", class_=\"attribute-list__description attribute-list__text\")[0].get_text()\n",
    "            life_ex = soup.find_all(\"span\", class_=\"attribute-list__description attribute-list__text\")[1].get_text()\n",
    "            group = soup.find_all(\"span\", class_=\"attribute-list__description attribute-list__text\")[2].get_text()\n",
    "            akc_rank = \"NA\"\n",
    "            weight = \"NA\"\n",
    "        else:\n",
    "            print(f\"Attributes are missing for '{dog_breed}'\")\n",
    "            temperment = f\"Attributes are missing for '{dog_breed}'\"\n",
    "            akc_rank = f\"Attributes are missing for '{dog_breed}'\"\n",
    "            height = f\"Attributes are missing for '{dog_breed}'\"\n",
    "            weight = f\"Attributes are missing for '{dog_breed}'\"\n",
    "            life_ex = f\"Attributes are missing for '{dog_breed}'\"\n",
    "            group = f\"Attributes are missing for '{dog_breed}'\"\n",
    "            \n",
    "        #####COLLECT DOG IMAGE#####    \n",
    "        try:\n",
    "            image_url = soup.find_all('img', class_=\"media-wrap__image lozad\")[1][\"data-src\"]\n",
    "        except:\n",
    "            print(f\"Image is missing for '{dog_breed}'\")\n",
    "            image_url = f\"Image is missing for '{dog_breed}'\"\n",
    "            \n",
    "        #####COLLECT DOG DESCRIPTION#####\n",
    "        try:\n",
    "            description = soup.find(\"div\", class_=\"breed-hero__footer\").get_text()\n",
    "            description = description.replace('\\n', '').strip(\" \")\n",
    "        except:\n",
    "            print(f\"Description is missing for '{dog_breed}'\")\n",
    "            description = f\"Description is missing for '{dog_breed}'\"\n",
    "            \n",
    "        #####COLLECT DOG CARE SCALES#####    \n",
    "        try:\n",
    "            brushing = soup.find_all(\"div\", class_=\"bar-graph__section\")[0][\"style\"].strip('width: ;')\n",
    "            shedding = soup.find_all(\"div\", class_=\"bar-graph__section\")[1][\"style\"].strip('width: ;')\n",
    "            energy = soup.find_all(\"div\", class_=\"bar-graph__section\")[2][\"style\"].strip('width: ;')\n",
    "            trainability = soup.find_all(\"div\", class_=\"bar-graph__section\")[3][\"style\"].strip('width: ;')\n",
    "            temperment_scale = soup.find_all(\"div\", class_=\"bar-graph__section\")[4][\"style\"].strip('width: ;')\n",
    "        except IndexError:\n",
    "            print(f\"Missing 'Care' Scales for '{dog_breed}'\")\n",
    "            brushing = f\"Missing 'Care' Scales for '{dog_breed}'\"\n",
    "            shedding = f\"Missing 'Care' Scales for '{dog_breed}'\"\n",
    "            energy = f\"Missing 'Care' Scales for '{dog_breed}'\"\n",
    "            trainability = f\"Missing 'Care' Scales for '{dog_breed}'\"\n",
    "            temperment_scale = f\"Missing 'Care' Scales for '{dog_breed}'\"\n",
    "        \n",
    "        #####COLLECT DOG COLORS #####\n",
    "        try:\n",
    "            table = soup.find_all('table')[0]\n",
    "        \n",
    "            color_list = []\n",
    "            final_color_list = []\n",
    "\n",
    "            for row in table.find_all('td'):\n",
    "                if 'Description' in row:\n",
    "                    continue\n",
    "                elif 'Standard Colors' in row:\n",
    "                    continue\n",
    "                elif 'Registration Code' in row:\n",
    "                    continue\n",
    "                elif \"Check Mark For Standard Color\" in row:\n",
    "                    continue\n",
    "                elif \"\\n\" in row:\n",
    "                    continue\n",
    "                else:\n",
    "                    color = row.get_text()\n",
    "                    color_list.append(color)\n",
    "            for i in color_list:\n",
    "                if \"Check Mark For Standard Color\" in i:\n",
    "                    continue\n",
    "                if \"\\n\" in i:\n",
    "                    continue\n",
    "                else:\n",
    "                    try:\n",
    "                        if int(i) > 0:\n",
    "                            continue\n",
    "                    except:\n",
    "                        final_color_list.append(i)\n",
    "        except:\n",
    "            print(f\"No Colors for '{dog_breed}'\")\n",
    "        \n",
    "        #####GO BACK TO BREED PAGE#####\n",
    "        browser.back()\n",
    "        \n",
    "        #####APPEND TO THE DICTIONARY#####\n",
    "        breeds_list_of_dicts.append({\"breed_name\" : dog_breed,\n",
    "                         \"temperment\": temperment,\n",
    "                         \"image\" : image_url,\n",
    "                         \"description\" : description,\n",
    "                         \"akc_rank\" : akc_rank,\n",
    "                         \"height\" : height,\n",
    "                         \"weight\" : weight,\n",
    "                         \"life_expectancy\" : life_ex,\n",
    "                         \"group\" : group,\n",
    "                         \"brushing_scale\" : brushing,\n",
    "                         \"shedding_scale\" : shedding,\n",
    "                         \"energy_scale\" : energy,\n",
    "                         \"trainability_scale\" : trainability,\n",
    "                         \"temperment_scale\" : temperment_scale,\n",
    "                         \"color_options\" : final_color_list\n",
    "                        })\n",
    "        time.sleep(1)\n",
    "        \n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breeds_list_of_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(breeds_list_of_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: chrome not reachable\n  (Session info: chrome=87.0.4280.141)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ee789d0101bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhtml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"html.parser\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jvolo\\anaconda4\\envs\\PythonData\\lib\\site-packages\\splinter\\driver\\webdriver\\__init__.py\u001b[0m in \u001b[0;36mhtml\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhtml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jvolo\\anaconda4\\envs\\PythonData\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mpage_source\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    677\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m         \"\"\"\n\u001b[1;32m--> 679\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET_PAGE_SOURCE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jvolo\\anaconda4\\envs\\PythonData\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32mC:\\Users\\jvolo\\anaconda4\\envs\\PythonData\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: chrome not reachable\n  (Session info: chrome=87.0.4280.141)\n"
     ]
    }
   ],
   "source": [
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "##### SOLO DOG COLLECTION ONLY #####\n",
    "####################################\n",
    "\n",
    "\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")\n",
    "\n",
    "#####COLLECT DOG BREED NAME#####\n",
    "dog_breed = soup.find(\"h1\").get_text()\n",
    "dog_breed = dog_breed.replace('\\n', '').strip(\" \")\n",
    "\n",
    "#####COLLECT DOG ATTRIBUTES#####\n",
    "attribute_block = soup.find_all(\"span\", class_=\"attribute-list__description\")\n",
    "\n",
    "if len(attribute_block) == 6:\n",
    "    temperment = soup.find(\"span\", class_=\"attribute-list__description attribute-list__text attribute-list__text--lg mb4 bpm-mb5 pb0 d-block\").get_text()\n",
    "    akc_rank = soup.find_all(\"span\", class_=\"attribute-list__description attribute-list__text\")[0].get_text()\n",
    "    height = soup.find_all(\"span\", class_=\"attribute-list__description attribute-list__text\")[1].get_text()\n",
    "    weight = soup.find_all(\"span\", class_=\"attribute-list__description attribute-list__text\")[2].get_text()\n",
    "    life_ex = soup.find_all(\"span\", class_=\"attribute-list__description attribute-list__text\")[3].get_text()\n",
    "    group = soup.find_all(\"span\", class_=\"attribute-list__description attribute-list__text\")[4].get_text()\n",
    "elif len(attribute_block) == 5: \n",
    "    temperment = soup.find(\"span\", class_=\"attribute-list__description attribute-list__text attribute-list__text--lg mb4 bpm-mb5 pb0 d-block\").get_text()\n",
    "    height = soup.find_all(\"span\", class_=\"attribute-list__description attribute-list__text\")[0].get_text()\n",
    "    weight = soup.find_all(\"span\", class_=\"attribute-list__description attribute-list__text\")[1].get_text()\n",
    "    life_ex = soup.find_all(\"span\", class_=\"attribute-list__description attribute-list__text\")[2].get_text()\n",
    "    group = soup.find_all(\"span\", class_=\"attribute-list__description attribute-list__text\")[3].get_text()\n",
    "    akc_rank = \"NA\"\n",
    "elif len(attribute_block) == 4:\n",
    "    temperment = soup.find(\"span\", class_=\"attribute-list__description attribute-list__text attribute-list__text--lg mb4 bpm-mb5 pb0 d-block\").get_text()\n",
    "    height = soup.find_all(\"span\", class_=\"attribute-list__description attribute-list__text\")[0].get_text()\n",
    "    life_ex = soup.find_all(\"span\", class_=\"attribute-list__description attribute-list__text\")[1].get_text()\n",
    "    group = soup.find_all(\"span\", class_=\"attribute-list__description attribute-list__text\")[2].get_text()\n",
    "    akc_rank = \"NA\"\n",
    "    weight = \"NA\"\n",
    "else:\n",
    "    print(f\"Attributes are missing for '{dog_breed}'\")\n",
    "    temperment = f\"Attributes are missing for '{dog_breed}'\"\n",
    "    akc_rank = f\"Attributes are missing for '{dog_breed}'\"\n",
    "    height = f\"Attributes are missing for '{dog_breed}'\"\n",
    "    weight = f\"Attributes are missing for '{dog_breed}'\"\n",
    "    life_ex = f\"Attributes are missing for '{dog_breed}'\"\n",
    "    group = f\"Attributes are missing for '{dog_breed}'\"\n",
    "\n",
    "#####COLLECT DOG IMAGE#####    \n",
    "try:\n",
    "    image_url = soup.find_all('img', class_=\"media-wrap__image lozad\")[1][\"data-src\"]\n",
    "except:\n",
    "    print(f\"Image is missing for '{dog_breed}'\")\n",
    "    image_url = f\"Image is missing for '{dog_breed}'\"\n",
    "\n",
    "#####COLLECT DOG DESCRIPTION#####\n",
    "try:\n",
    "    description = soup.find(\"div\", class_=\"breed-hero__footer\").get_text()\n",
    "    description = description.replace('\\n', '').strip(\" \")\n",
    "except:\n",
    "    print(f\"Description is missing for '{dog_breed}'\")\n",
    "    description = f\"Description is missing for '{dog_breed}'\"\n",
    "\n",
    "#####COLLECT DOG CARE SCALES#####    \n",
    "try:\n",
    "    brushing = soup.find_all(\"div\", class_=\"bar-graph__section\")[0][\"style\"].strip('width: ;')\n",
    "    shedding = soup.find_all(\"div\", class_=\"bar-graph__section\")[1][\"style\"].strip('width: ;')\n",
    "    energy = soup.find_all(\"div\", class_=\"bar-graph__section\")[2][\"style\"].strip('width: ;')\n",
    "    trainability = soup.find_all(\"div\", class_=\"bar-graph__section\")[3][\"style\"].strip('width: ;')\n",
    "    temperment_scale = soup.find_all(\"div\", class_=\"bar-graph__section\")[4][\"style\"].strip('width: ;')\n",
    "except IndexError:\n",
    "    print(f\"Missing 'Care' Scales for '{dog_breed}'\")\n",
    "    brushing = f\"Missing 'Care' Scales for '{dog_breed}'\"\n",
    "    shedding = f\"Missing 'Care' Scales for '{dog_breed}'\"\n",
    "    energy = f\"Missing 'Care' Scales for '{dog_breed}'\"\n",
    "    trainability = f\"Missing 'Care' Scales for '{dog_breed}'\"\n",
    "    temperment_scale = f\"Missing 'Care' Scales for '{dog_breed}'\"\n",
    "\n",
    "#####COLLECT DOG COLORS #####\n",
    "try:\n",
    "    table = soup.find_all('table')[0]\n",
    "\n",
    "    color_list = []\n",
    "    final_color_list = []\n",
    "\n",
    "    for row in table.find_all('td'):\n",
    "        if 'Description' in row:\n",
    "            continue\n",
    "        elif 'Standard Colors' in row:\n",
    "            continue\n",
    "        elif 'Registration Code' in row:\n",
    "            continue\n",
    "        elif \"Check Mark For Standard Color\" in row:\n",
    "            continue\n",
    "        elif \"\\n\" in row:\n",
    "            continue\n",
    "        else:\n",
    "            color = row.get_text()\n",
    "            color_list.append(color)\n",
    "        for i in color_list:\n",
    "            if \"Check Mark For Standard Color\" in i:\n",
    "                continue\n",
    "            if \"\\n\" in i:\n",
    "                continue\n",
    "            else:\n",
    "                try:\n",
    "                    if int(i) > 0:\n",
    "                        continue\n",
    "                except:\n",
    "                    final_color_list.append(i)\n",
    "except:\n",
    "    print(f\"No Colors for '{dog_breed}'\")\n",
    "\n",
    "#####GO BACK TO BREED PAGE#####\n",
    "browser.back()\n",
    "\n",
    "#####APPEND TO THE DICTIONARY#####\n",
    "breeds_list_of_dicts.append({\"breed_name\" : dog_breed,\n",
    "                             \"temperment\": temperment,\n",
    "                             \"image\" : image_url,\n",
    "                             \"description\" : description,\n",
    "                             \"akc_rank\" : akc_rank,\n",
    "                             \"height\" : height,\n",
    "                             \"weight\" : weight,\n",
    "                             \"life_expectancy\" : life_ex,\n",
    "                             \"group\" : group,\n",
    "                             \"brushing_scale\" : brushing,\n",
    "                             \"shedding_scale\" : shedding,\n",
    "                             \"energy_scale\" : energy,\n",
    "                             \"trainability_scale\" : trainability,\n",
    "                             \"temperment_scale\" : temperment_scale,\n",
    "                             \"color_options\" : final_color_list\n",
    "                            })\n",
    "time.sleep(1)\n",
    "\n",
    "#browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breeds_df = DataFrame(breeds_list_of_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breeds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breeds_df.to_csv('breeds_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
